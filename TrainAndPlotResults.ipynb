{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ee2d3c9-1ed6-4a19-8b67-d455762faa2f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c332d56-9e54-4ece-a557-825827f95576",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "from components.AttractorLayer import AttractorLayer\n",
    "from components.RadarLoader import RadarLoader\n",
    "\n",
    "seq_name = \"2020-02-28-13-13-43\"\n",
    "%run carrada_utils/scripts/set_path.py 'components/carrada_datasets/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a93da4-4869-4218-a1b5-17138dc7401b",
   "metadata": {},
   "source": [
    "## Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aecf9fe9-c54d-4440-9ff6-a9dc996e6f60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((3*3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd5c3095-fd26-4c62-a244-ad7cbea0cad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAU = 1  # TODO: I don't know whether this is important\n",
    "INTENSITY =1.0\n",
    "BETA =300  # TODO : Check this\n",
    "SIGMA = 3.0 # TODO: Check this\n",
    "SHIFT = 0.0 # TODO : Check this\n",
    "CUTOFF_DIST = 10 # TODO : Change this\n",
    "X_EYE = 1.0\n",
    "Y_EYE = 1.0\n",
    "NR_OF_PASSES = 4\n",
    "\n",
    "K_INHIB = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fd71d0-61e3-4fc0-b6eb-50bfb6e9e0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = RadarLoader(seq_name)\n",
    "data, size_bf = data_loader.get_range_angle_stream_data(clip_and_normalize=True, resize=(64,64))\n",
    "data_diff_normalized = data_loader.get_range_angle_stream_data_differentiated(clip_and_normalize=True, resize=(64,64))\n",
    "raw_camera_data = data_loader.get_color_image_datastream(resize=(64,64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2bdd82-db3b-43d7-a2f5-fd28a7edf272",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load parameters and network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b767f39f-a3aa-4a74-91dd-9aab32621bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_layer = AttractorLayer(\n",
    "        tau=TAU,\n",
    "        intensity=INTENSITY,\n",
    "        cutoff_dist=CUTOFF_DIST,\n",
    "        sigma=SIGMA,\n",
    "        shift=SHIFT,\n",
    "        beta=BETA,\n",
    "        k=K_INHIB,\n",
    "        clip=True,\n",
    "        x_eye=X_EYE,\n",
    "        y_eye=Y_EYE,\n",
    ")\n",
    "\n",
    "attr_layer.set_weights()\n",
    "attr_layer.save_network(file_path=\"components/network_weights/threes_win.npy\")\n",
    "\n",
    "#attr_layer.load_network(file_path=\"components/network_weights/threes_win.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e7318d-3658-442e-86ad-c3d3afe66812",
   "metadata": {},
   "source": [
    "# Run process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee5ff45-1f12-4dae-9af7-0026ca8d7dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_act = []\n",
    "neuron_act_final = []\n",
    "for data_entry in data_diff_normalized:\n",
    "    # Forward pass\n",
    "    activities_step = attr_layer.forward_pass_visualization(data_entry.flatten(), number_of_passes=NR_OF_PASSES)\n",
    "    # Get neuron activities\n",
    "    neuron_act.append(activities_step[0].copy())\n",
    "    neuron_act_final.append(activities_step[NR_OF_PASSES-1].copy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441556ad-ef1a-4f99-8da1-a6984aeff85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "IO_CUTOFF = 0.4\n",
    "output_ = []\n",
    "for i in range(0,len(neuron_act)):\n",
    "    # Use input and activities to get output\n",
    "    data_entry_clipped = neuron_act_10[i].copy()\n",
    "    activities_step_clipped = data_diff_normalized[i].copy()\n",
    "    #data_entry_clipped[data_entry_clipped < 0.1] = 0.0\n",
    "    #activities_step_clipped[activities_step_clipped < 0.1] = 0.0\n",
    "    output_step =  data_entry_clipped * activities_step_clipped\n",
    "    output_step[output_step < 0.001] = 0.0\n",
    "    output_step[output_step > 0.0009] = 1.0\n",
    "    output_.append(output_step.copy())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b73184b-9eb3-4e84-ac6d-1c4648cd6065",
   "metadata": {},
   "source": [
    "# Get annotations and calculate score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cb30d7-9c70-429c-a857-08a9a82f38d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dense_, sparse_, box_, sp_mp_, sp_mp_vis_ = data_loader.visualize_annotations(differentiated=True, size_bf=size_bf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cebcf7-8e12-4c53-b16d-739858dbca40",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_annot = []\n",
    "predicted_location_network = []\n",
    "\n",
    "difference_in_location = []\n",
    "it_i = 0\n",
    "for data_entry in sp_mp_:\n",
    "    s_ = np.zeros((64,64))\n",
    "    tt_ = np.zeros((64,64))\n",
    "    for sub_entry in data_entry:\n",
    "        s_[sub_entry[0] // 4][sub_entry[1] // 4] = 1\n",
    "        loc_ = np.argmax(neuron_act_10[it_i])\n",
    "        tt_[loc_// 64][loc_ %64]= 1\n",
    "        \n",
    "        diff_loc_ = np.sqrt(((loc_// 64) - sub_entry[0]//4)**2 + ((loc_ %64) - sub_entry[1]//4)**2)\n",
    "        \n",
    "        difference_in_location.append(diff_loc_)\n",
    "        break\n",
    "        \n",
    "    predicted_location_network.append(tt_.copy())    \n",
    "    ground_truth_annot.append(s_.copy())\n",
    "    it_i +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccef2d5e-638a-4d5d-b9f2-ef37133d1a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(difference_in_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d7a860-dfe5-4534-aadd-75fadb889a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUTOFF = 0.5\n",
    "mIoU_dense = []\n",
    "mDice_dense = []\n",
    "mIoU_sparse = []\n",
    "mDice_sparse = []\n",
    "for i in range(0,len(dense_)):\n",
    "    A_acts = neuron_act[i].copy()\n",
    "    A_acts[A_acts < 0.1] = 0\n",
    "    A_acts[A_acts > 0.09] = 1\n",
    "    B_gt_dense = dense_[i].copy() * 1\n",
    "    B_gt_sparse = sparse_[i].copy() * 1\n",
    "     \n",
    "    A_B_intersection_dense = A_acts.copy()\n",
    "    A_B_intersection_dense[B_gt_dense == 1.0] = 1.0\n",
    "    A_B_intersection_dense[B_gt_dense != 1.0] = 0.0\n",
    "    \n",
    "    A_B_union_dense = B_gt_dense.copy()\n",
    "    A_B_union_dense[A_acts > 0] = 1.0\n",
    "    \n",
    "    if np.sum(A_B_union_dense) <=0.001:\n",
    "        continue\n",
    "    mIoU_dense.append(np.sum(A_B_intersection_dense) / np.sum(A_B_union_dense))\n",
    "    mDice_dense.append(np.sum(A_B_intersection_dense) * 2 / (np.sum(B_gt_dense) + np.sum(A_acts)))\n",
    "    \n",
    "     \n",
    "    A_B_intersection_sparse = A_acts.copy()\n",
    "    A_B_intersection_sparse[B_gt_sparse == 1.0] = 1.0\n",
    "    A_B_intersection_sparse[B_gt_sparse != 1.0] = 0.0\n",
    "    \n",
    "    A_B_union_sparse = B_gt_sparse.copy()\n",
    "    A_B_union_sparse[A_acts > 0] = 1.0\n",
    "    if np.sum(A_B_union_sparse) <=0.001:\n",
    "        continue\n",
    "    mIoU_sparse.append(np.sum(A_B_intersection_sparse) / np.sum(A_B_union_sparse))\n",
    "    mDice_sparse.append(np.sum(A_B_intersection_sparse) * 2 / (np.sum(B_gt_sparse) + np.sum(A_acts)))\n",
    "    \n",
    "    \n",
    "title_string = f\"Losses \\n        mIoU_dense: {np.mean(mIoU_dense[40:]):.6f}\\n     mIoU_sparse: {np.mean(mIoU_sparse[40:]):.6f}\\n\"\n",
    "print(title_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6508e844-b915-400c-8d42-b1f8ab80cc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig,((ax1, ax2, ax6), (ax3, ax4, ax5))= plt.subplots(2, 3, figsize=(18,5), dpi=100)\n",
    "fig.suptitle(title_string, fontsize=10)\n",
    "\n",
    "# Ground Truth Comparison\n",
    "gt_comparison = np.zeros((len(neuron_act), 64,64,3))\n",
    "gt_comparison[:,:,:,1] = ground_truth_annot \n",
    "gt_comparison[:,:,:,2] = predicted_location_network\n",
    "\n",
    "ax1.tick_params(axis='both',labelsize=8)\n",
    "ax1.set_title(\"Ground Truth vs. Predicted Location\",fontsize=10)\n",
    "gt_comp_map = ax1.imshow(gt_comparison[0], cmap='hot', interpolation='none')\n",
    "\n",
    "# Neuron Activities\n",
    "ax2.tick_params(axis='both',labelsize=8)\n",
    "ax2.set_title(f\"Neuron Activities after {NR_OF_PASSES} passes\",fontsize=10)\n",
    "cell_act_map = ax2.imshow(np.array(neuron_act_final[0]), cmap='hot', interpolation='none')\n",
    "\n",
    "# Annotated Neuron Activities\n",
    "annotated_neuron_act = np.zeros((len(neuron_act), 64,64,3))\n",
    "annotated_neuron_act[:,:,:,0] = neuron_act_final / np.max(neuron_act_final)\n",
    "annotated_neuron_act[:,:,:,1] = dense_\n",
    "\n",
    "ax6.tick_params(axis='both',labelsize=8)\n",
    "ax6.set_title(\"Neuron Activities with Annotation\",fontsize=10)\n",
    "cell_act_map_w_annot = ax6.imshow(annotated_neuron_act[0], cmap='hot', interpolation='none')\n",
    "\n",
    "# Differentiated Input for the data\n",
    "ax3.tick_params(axis='both',labelsize=8)\n",
    "ax3.set_title(\"Differentiated Input\",fontsize=10)\n",
    "input_diff_map = ax3.imshow(np.array(data_diff_normalized[0]), cmap='hot',interpolation='none')\n",
    "\n",
    "# Raw data input\n",
    "ax4.tick_params(axis='both',labelsize=8)\n",
    "ax4.set_title(\"Raw Data Input\",fontsize=10)\n",
    "input_map = ax4.imshow(np.array(data[1]), cmap='hot', interpolation='none')\n",
    "\n",
    "# Raw RGB Camera data\n",
    "ax5.tick_params(axis='both',labelsize=8)\n",
    "ax5.set_title(\"Raw Camera RGB Data\",fontsize=10)\n",
    "rgb_cam_data = ax5.imshow(np.array(raw_camera_data[1]), interpolation='none')]\n",
    "\n",
    "\n",
    "def init():\n",
    "    cell_act_map_w_annot.set_data(annotated_neuron_act[0])\n",
    "    gt_comp_map.set_data(gt_comparison[0])\n",
    "    cell_act_map.set_data(np.array(neuron_act[0]))\n",
    "    input_diff_map.set_data(np.array(data_diff_normalized[0]))\n",
    "    input_map.set_data(np.array(data[1]))\n",
    "    rgb_cam_data.set_data(np.array(raw_camera_data[1]))\n",
    "    return [cell_act_map_w_annot, cell_act_map, input_diff_map, input_map, rgb_cam_data]\n",
    "\n",
    "# animation function.  This is called sequentially\n",
    "def animate(i):\n",
    "    cell_act_map_w_annot.set_data(annotated_neuron_act[i])\n",
    "    gt_comp_map.set_data(gt_comparison[i])\n",
    "    cell_act_map.set_data(np.array((neuron_act[i])))\n",
    "    input_diff_map.set_data(np.array(data_diff_normalized[i]))\n",
    "    input_map.set_data(np.array(data[i+1]))\n",
    "    rgb_cam_data.set_data(np.array(raw_camera_data[i+1]))\n",
    "    return [cell_act_map_w_annot, cell_act_map, input_diff_map, input_map, rgb_cam_data]\n",
    "\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                               frames=150, interval=1, blit=True)\n",
    "\n",
    "anim.save('animations/final_anim1_sp_cam_pass_10.gif', fps=10)\n",
    "\n",
    "from IPython.display import Image, display\n",
    "with open('animations/final_anim1_sp_cam_pass_10.gif','rb') as file:\n",
    "    display(Image(file.read()))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a500db3d-63e0-4cda-b3e3-08f3cbe339a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe6dffc-600a-451d-93a7-016a4af40d37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8460021f-85fa-4968-822d-9b7a26daea63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fd5d72-3fff-47cd-8005-1969f3ed2c00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa3079a-c6e8-4c7e-825d-e75d4c8be739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0271e0e4-0fae-46cf-8e92-4416e974c171",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
